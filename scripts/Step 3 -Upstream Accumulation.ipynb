{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis\n",
    "This notebook compute cumulative biogas potential for the pipeline segments. \n",
    "1. Read in the edge list computed from the pipeline segments. This includes the edge ID, the downstream edge ID, and the amount of biogas potential at the edge source. \n",
    "2. Build a graph and then iterate through node on the graph, trace downstream, and tally cumulative downstream biogas potential values.\n",
    "3. Export as a csv and shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data in from the BasePipelines shapefile\n",
    "gdf_Pipelines = gpd.read_file('../data/processed/BasePipelines.shp')\n",
    "gdf_Pipelines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the field name variables\n",
    "source_fld = 'edge_ID'\n",
    "target_fld = 'downstream'\n",
    "weight_fld = 'Waste'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and populate the graph\n",
    "* Create a multi-directional graph\n",
    "* Iterate through the edge list and add add edges from the source/downstream nodes & weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct the graph from the dataframe\n",
    "G = nx.from_pandas_edgelist(gdf_Pipelines,\n",
    "                            source=source_fld,\n",
    "                            target=target_fld,\n",
    "                            edge_attr=True,\n",
    "                            create_using=nx.MultiDiGraph\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset terminal nodes\n",
    "gdf_terminal = gdf_Pipelines[gdf_Pipelines['downstream'].str.contains(\"T\")]\n",
    "gdf_terminal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get descendents\n",
    "network_dict = {}\n",
    "for terminal_node in gdf_terminal['downstream'].values:\n",
    "    network_dict[terminal_node] = terminal_node\n",
    "    for upstream_id in  nx.ancestors(G,terminal_node):\n",
    "        network_dict[upstream_id] = terminal_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attach attribute to pipeline GDF\n",
    "gdf_Pipelines['Network'] = gdf_Pipelines['downstream'].apply(lambda x: network_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute total upstream biogas potential \n",
    "Iterate through each \"from\" node and find all its upstream nodes and sum their collective biogas potential values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that finds all upstream nodes and compute total upstream waste\n",
    "def getUpstream(node_id):\n",
    "    #Get a list of nodes downstream of the current node\n",
    "    up_nodes = nx.ancestors(G,node_id)\n",
    "    #Add the source node itself\n",
    "    up_nodes.add(node_id)\n",
    "    #return the sum of the weight field for all selected records\n",
    "    return int(gdf_Pipelines.loc[gdf_Pipelines[source_fld].isin(list(up_nodes)),weight_fld].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the function \n",
    "gdf_Pipelines['AccumWaste'] = gdf_Pipelines[source_fld].apply(getUpstream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export results to a shapefile\n",
    "gdf_Pipelines.to_file('../data/processed/AccumWaste.shp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create node file\n",
    "Here we want to extract the vertices from the gdf_Pipeline features to its own feature class. \n",
    "\n",
    "We start by pulling out the start point of each LineString feature to a new dataframe, but this still lacks the end point of the most downstream point of each network (i.e. where they connect to the pipeline). So we then extract the end points and append those to the start points, removing duplicates (i.e. nodes that occur at the end of one feature and the start of another). \n",
    "\n",
    "Finally, we append the edge attribute data to each node feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform to WGS84 (to extract lat/long coordinates)\n",
    "gdfWGS84 = gdf_Pipelines.to_crs(4326)\n",
    "gdfWGS84.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the first points in each segment\n",
    "gdfWGS84['longitude'] = gdfWGS84['geometry'].apply(lambda x: x.coords[0][0])\n",
    "gdfWGS84['latitude'] = gdfWGS84['geometry'].apply(lambda x: x.coords[0][1])\n",
    "df_First = (gdfWGS84[['edge_ID','latitude','longitude']]\n",
    "             .reset_index()\n",
    "             .drop('index',axis=1))\n",
    "df_First.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the last points in each segment\n",
    "gdfWGS84['longitude'] = gdfWGS84['geometry'].apply(lambda x: x.coords[-1][0])\n",
    "gdfWGS84['latitude'] = gdfWGS84['geometry'].apply(lambda x: x.coords[-1][1])\n",
    "df_Last = (gdfWGS84[['downstream','latitude','longitude']]\n",
    "            .reset_index()\n",
    "            .rename({'downstream':'edge_ID'},axis=1)\n",
    "            .drop('index',axis=1))\n",
    "df_Last.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the two, dropping duplicates\n",
    "df_Nodes = df_First.append(df_Last,ignore_index=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join attributes from the edge dataframe\n",
    "gdf_Out = gdf_Pipelines.merge(df_Nodes,on='edge_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute edge length, in km\n",
    "gdf_Out['length_km'] = gdf_Out['geometry'].length / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the geometry column\n",
    "gdf_Out.drop(columns=['geometry'],axis=1,inplace=True)\n",
    "gdf_Out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns and export as a CSV file\n",
    "gdf_Out.rename({'edge_ID':'node_ID',\n",
    "                'downstream':'downstream_ID'},\n",
    "               axis=1).to_csv(\"../data/processed/Nodes.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a metadata file\n",
    "with open(\"../data/processed/Nodes_readme.txt\",\"w\") as metadata:\n",
    "    metadata.write('''\n",
    "node_id\\t\\tThe internal ID of the node\n",
    "\n",
    "downstream_id\\tThe internal ID of the node immediately downstream if the node\n",
    "\\t\\t[A \"T\" indicates its a terminal node, i.e. connects to existing pipeline]\n",
    "\n",
    "Fac_ID\\t\\tThe biogas facility ID, if the node originates from it (\"NA\" indicates its a connector)\n",
    "\n",
    "Waste\\t\\tWaste originating at the node (if a biogas source)\n",
    "\n",
    "Biogas\\t\\tBiogas potential at the node (if a biogas source)\n",
    "\n",
    "Type\\t\\t\"Source\" = node occurs at a biogas source\n",
    "\\t\\t\"Route\" = node is a junciton along the route form sources to exiting pipeline\n",
    "\\t\\t\"Output\"= node occurs where the route meets an existing pipeline\n",
    "\n",
    "Connection\\t\"Transmission\" = output node connects to an existing transmission pipeline\n",
    "\\t\\t\"Distribution\" = output node connects to an existing distribution pipeline\n",
    "\\t\\tNA\"/None = node is not an output node\n",
    "\n",
    "Network\\t\\t[NEED VERIFICATION]ID of the network to which the node belongs. \n",
    "\\t\\t(Each network has its one connection to existing pipeline)\n",
    "\n",
    "AccumWaste\\tAccumulated upstream Waste at the node\n",
    "\n",
    "latitude/longitude Coordinates of the node\n",
    "    ''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
